{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "spare-drawing",
   "metadata": {},
   "source": [
    "## Configure EnvironmentÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-investigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imagiq.federated as iqf\n",
    "import numpy as np\n",
    "import torch\n",
    "from imagiq.models import Model, load_model\n",
    "from imagiq.datasets import NIHDataset\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    ScaleIntensityd,\n",
    "    SqueezeDimd,\n",
    "    AddChanneld,\n",
    "    AsChannelFirstd,\n",
    "    Lambdad,\n",
    "    ToTensord,\n",
    "    Resized,\n",
    "    RandRotated,\n",
    "    RandFlipd,\n",
    "    RandHistogramShiftd,\n",
    "    RandZoomd,\n",
    "    RandGaussianNoised,\n",
    "    CastToTyped\n",
    ")\n",
    "\n",
    "from monai.networks.nets import se_resnet50, se_resnet101, densenet121, densenet169, densenet201\n",
    "from monai.data import CacheDataset\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#not neccessary needed\n",
    "import gc\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-preserve",
   "metadata": {},
   "source": [
    "## Create and start local nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-radiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "port = 18010\n",
    "node = iqf.nodes.Node(\"localhost\", port)\n",
    "node.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-drink",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-reasoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = NIHDataset( \"training\", download=[0])\n",
    "test_ds = NIHDataset(\"test\", download=[0])\n",
    "val_ds = NIHDataset(\"validation\", download=[0])\n",
    "\n",
    "def rand_idx(i, j):\n",
    "    while True:\n",
    "        idx = np.random.randint(j)\n",
    "        if idx != i:\n",
    "            return idx\n",
    "\n",
    "def generate_data(dataset):\n",
    "    tmps = [[] for _ in range(5)]\n",
    "    for i, data in enumerate(dataset):\n",
    "        if data[\"label\"][1]:  # if atelectasis, more likely go in node1\n",
    "            data[\"label\"] = 1-data[\"label\"][0]\n",
    "            if np.random.rand() < 0.8:\n",
    "                tmps[0].append(data)\n",
    "            else:\n",
    "                tmps[rand_idx(0, 5)].append(data)\n",
    "        elif data[\"label\"][3]:  # effusion, more likely go in node2\n",
    "            data[\"label\"] = 1-data[\"label\"][0]\n",
    "            if np.random.rand() < 0.8:\n",
    "                tmps[1].append(data)\n",
    "            else:\n",
    "                tmps[rand_idx(1, 5)].append(data)\n",
    "        elif data[\"label\"][4]:  # infiltration, more likely go in node3\n",
    "            data[\"label\"] = 1-data[\"label\"][0]\n",
    "            if np.random.rand() < 0.8:\n",
    "                tmps[2].append(data)\n",
    "            else:\n",
    "                tmps[rand_idx(2, 5)].append(data)\n",
    "        elif data[\"label\"][6]:  # nodule, more likely go in node4\n",
    "            data[\"label\"] = 1-data[\"label\"][0]\n",
    "            if np.random.rand() < 0.8:\n",
    "                tmps[3].append(data)\n",
    "            else:\n",
    "                tmps[rand_idx(3, 5)].append(data)\n",
    "        else:  # for other findings \n",
    "            data[\"label\"] = 1-data[\"label\"][0]\n",
    "            tmps[rand_idx(-1, 5)].append(data)\n",
    "    return tmps\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "train_tmps = generate_data(train_ds)\n",
    "test_tmps  = generate_data(test_ds)\n",
    "val_tmps = generate_data(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-services",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose([\n",
    "    LoadImaged(\"image\"), \n",
    "    Lambdad(\"image\", func=lambda x: np.mean(x, axis=2) if len(x.shape) == 3 else x),\n",
    "    AsChannelFirstd(\"image\"),\n",
    "    AddChanneld(\"image\"),\n",
    "    ScaleIntensityd(\"image\"),\n",
    "    Resized(\"image\", spatial_size=(224,224), mode=\"nearest\"),\n",
    "    RandRotated(\"image\", range_x=15, prob=0.5, keep_size=True),\n",
    "    RandFlipd(\"image\", spatial_axis=0, prob=0.5),\n",
    "    RandZoomd(\"image\", min_zoom=0.9, max_zoom=1.1, prob=0.5, keep_size=True)\n",
    "])\n",
    "\n",
    "val_transforms = Compose([\n",
    "    LoadImaged(\"image\"),\n",
    "    Lambdad(\"image\", func=lambda x: np.mean(x, axis=2) if len(x.shape) == 3 else x),\n",
    "    AsChannelFirstd(\"image\"),\n",
    "    AddChanneld(\"image\"),\n",
    "    ScaleIntensityd(\"image\"),\n",
    "    Resized(\"image\", spatial_size=(224,224), mode=\"nearest\")\n",
    "])\n",
    "\n",
    "biasIdx = 0\n",
    "train_dataset = CacheDataset(train_tmps[biasIdx], train_transforms)\n",
    "test_dataset  = CacheDataset(test_tmps[biasIdx], val_transforms)\n",
    "val_dataset  = CacheDataset(val_tmps[biasIdx], val_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-tolerance",
   "metadata": {},
   "source": [
    "## Prepare model bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-drive",
   "metadata": {},
   "outputs": [],
   "source": [
    "node.add_model([\n",
    "    Model(se_resnet50(spatial_dims=2, in_channels=1, num_classes=2), 'model_1'),\n",
    "    Model(se_resnet101(spatial_dims=2, in_channels=1, num_classes=2), 'model_2'),\n",
    "    Model(se_resnet50(spatial_dims=2, in_channels=1, num_classes=2), 'model_3'),\n",
    "    Model(se_resnet101(spatial_dims=2, in_channels=1, num_classes=2), 'model_4'),\n",
    "    Model(se_resnet50(spatial_dims=2, in_channels=1, num_classes=2), 'model_5')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the model that the node has received\n",
    "node.model_bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the following if your machine has a low GPU memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-insured",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Train models\n",
    "histories = [None] * len(node.model_bench)\n",
    "\n",
    "for idx, model in enumerate( node.model_bench ):\n",
    "    print( model.name ) \n",
    "    optimizer = torch.optim.Adam( model.net.parameters(), 5e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau( optimizer, mode='min', factor=0.1, patience=5)    \n",
    "    histories[idx] = model.train(\n",
    "        train_dataset,\n",
    "        torch.nn.CrossEntropyLoss(),\n",
    "        optimizer,\n",
    "        epochs=1,\n",
    "        metrics=[\"AUC\"],\n",
    "        batch_size=5,\n",
    "        device=\"cuda:0\",\n",
    "        validation_dataset=val_dataset,\n",
    "        scheduler=scheduler\n",
    "    )\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize=(20, 6) ) \n",
    "\n",
    "plt.subplot( 1, 2, 1)\n",
    "for idx in range( len(histories) ):\n",
    "    plt.plot( histories[idx]['val_loss'] )\n",
    "plt.legend( [model.name for model in node.model_bench] )\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title( 'epoch vs validation loss' )\n",
    "\n",
    "plt.subplot( 1, 2, 2 )\n",
    "for idx in range( len(histories) ):\n",
    "    plt.plot( histories[idx]['val_auc'] )\n",
    "plt.legend( [model.name for model in node.model_bench] )\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('auc')\n",
    "plt.title( 'epoch vs validation auc' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-punch",
   "metadata": {},
   "source": [
    "## Create Ensemble with validation dataset\n",
    "**size**: is the number of model you want to combine<br>\n",
    "**models**:default is all models in model bench, but you can pass in different models<br>\n",
    "**diversity_measure**: default to be auc. You can also write gd for generalized_diversity.<br>\n",
    "**voted_method**:votes aggregating measurement. \"majority\" and \"probability\" available<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = node.create_ensemble(\n",
    "    size=3,\n",
    "    dataset=val_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    models = node.model_bench,\n",
    "    vote_method=\"probability\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-season",
   "metadata": {},
   "source": [
    "## Ensemble result on validation data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-alarm",
   "metadata": {},
   "source": [
    "### Create Ensemble model\n",
    "**percentage**: default is 0. Only works when you have *gd* for diversity_measure, which means the percentage that the diveristy will takes in the selection standard. For example, with percentage equals to 0.2, the equation would be 0.8*auc +0.2*diversity <br>\n",
    "**method**: \"normal\":create an ensemble by trying all combinations, \"hill_climbing\" create an ensemble with Optimized method, takes shorted time, may lead to a comparable worst result <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-metropolitan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ensemble.create(percentage=0,method=\"normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-hypothesis",
   "metadata": {},
   "source": [
    "### Return Ensemble model by hill climbing method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-cemetery",
   "metadata": {},
   "source": [
    "Similar to all combinations\n",
    "**plot_chart**: Default to false. True to plot a chart of auc and the time it compares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.create(percentage=0,plot_chart=True,method=\"hill_climbing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-cholesterol",
   "metadata": {},
   "source": [
    "## Check the Result Records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-power",
   "metadata": {},
   "source": [
    "**uid**: the unique id for that record<br>\n",
    "**time**: timestamp of the time you get the result<br>\n",
    "**size**: the number of model you selected<br>\n",
    "**function_name**: through which function you get this result,\"evaluate on test_dataset\",\"hill_climbing\",\"ensemble_size_k\"<br>\n",
    "**diversity_measure**,**voted_measure** -- whatever you use in that method<br>\n",
    "**model_bench**: the model pool you entered -- model_uids<br>\n",
    "**selected_models**: A dictionary. This is the result we get with two section,\"uid\" and \"name\". You can use uid for future prediction<br>\n",
    "\n",
    "**diversity_score**,**ensemble_val_auc**,**ensemble_val_acc**:the result evaluation you have -- for validations <br>\n",
    "**ensemble_test_auc**,**ensemble_test_acc**,**pred**:the result evaluation you have -- for test dataset<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-charles",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-compound",
   "metadata": {},
   "source": [
    "## Ensemble result on test data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-invention",
   "metadata": {},
   "source": [
    "**batch size**: default with 1<br>\n",
    "**ensemble_measure**: similar to above description<br>\n",
    "**test**: Default is False - predict with validation data, True to work with test data<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-participant",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the best result to result_model\n",
    "ensemble.set_best_ensemble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-inside",
   "metadata": {},
   "source": [
    "## Save all result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.save(\"/Result\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
