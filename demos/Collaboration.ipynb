{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "marked-multimedia",
   "metadata": {},
   "source": [
    "# Collaboration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-smile",
   "metadata": {},
   "source": [
    "## Configure environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dated-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to change the working directory.\n",
    "# TODO: pip install will resolve this issue...\n",
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "artistic-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from imagiq.federated.nodes import Node\n",
    "from imagiq.models import Model\n",
    "from imagiq.datasets import CBISDDSMDataset, LoadBreastDensity, LoadBreastDensityd\n",
    "from imagiq.utils.file_systems import remove, mkdir\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    ScaleIntensityd,\n",
    "    SqueezeDimd,\n",
    "    AddChanneld,\n",
    "    AsChannelFirstd,\n",
    "    Lambdad,\n",
    "    ToTensord,\n",
    "    Resized,\n",
    "    RandRotated,\n",
    "    RandFlipd,\n",
    "    RandHistogramShiftd,\n",
    "    RandGaussianNoised,\n",
    "    RandZoomd,\n",
    "    RepeatChanneld, \n",
    "    NormalizeIntensityd\n",
    ")\n",
    "from monai.networks.nets import densenet121, densenet169, se_resnet50, se_resnet101, se_resnet152\n",
    "from monai.data import CacheDataset\n",
    "import sys\n",
    "import pandas as pd\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-mining",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "successful-eagle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cbisddsm.csv: 16.0kB [00:01, 8.41kB/s]                            \n",
      "images_001.zip: 0.00B [00:00, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "downloaded file: /Users/navya/.imagiq/datasets/CBISDDSM/cbisddsm.csv.\n",
      "Expected md5 is None, skip md5 check for file /Users/navya/.imagiq/datasets/CBISDDSM/cbisddsm.csv.\n",
      "Downloading images_001.zip. This may take several minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "images_001.zip: 3.81GB [01:55, 35.5MB/s]                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "downloaded file: /Users/navya/.imagiq/datasets/CBISDDSM/images_001.zip.\n",
      "Expected md5 is None, skip md5 check for file /Users/navya/.imagiq/datasets/CBISDDSM/images_001.zip.\n",
      "Expected md5 is None, skip md5 check for file /Users/navya/.imagiq/datasets/CBISDDSM/images_001.zip.\n",
      "Update [0008|103e]: Calc-Test_P_00127_RIGHT_MLO.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00127_RIGHT_MLO.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00127_RIGHT_CC.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00127_RIGHT_CC.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00180_LEFT_CC.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00180_LEFT_CC.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00180_LEFT_MLO.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00180_LEFT_MLO.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00202_RIGHT_MLO.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00202_RIGHT_MLO.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00202_RIGHT_CC.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00202_RIGHT_CC.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00038_RIGHT_CC.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00038_RIGHT_CC.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00038_LEFT_CC.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00038_LEFT_CC.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00038_RIGHT_MLO.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00038_RIGHT_MLO.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00038_LEFT_MLO.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00038_LEFT_MLO.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00041_LEFT_MLO.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00041_LEFT_MLO.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00041_LEFT_CC.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00041_LEFT_CC.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00077_RIGHT_MLO.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00077_RIGHT_MLO.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00077_RIGHT_CC.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00077_RIGHT_CC.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00077_LEFT_CC.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00077_LEFT_CC.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00077_LEFT_MLO.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00077_LEFT_MLO.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00150_RIGHT_MLO.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00150_RIGHT_MLO.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00195_LEFT_CC.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00195_LEFT_CC.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00195_LEFT_MLO.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00195_LEFT_MLO.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00132_LEFT_MLO.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00132_LEFT_MLO.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00140_RIGHT_CC.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00140_RIGHT_CC.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00140_RIGHT_MLO.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00140_RIGHT_MLO.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00140_LEFT_MLO.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00140_LEFT_MLO.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00140_LEFT_CC.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00140_LEFT_CC.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00214_LEFT_MLO.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00214_LEFT_MLO.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00214_LEFT_CC.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00214_LEFT_CC.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00214_RIGHT_MLO.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00214_RIGHT_MLO.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00164_RIGHT_CC.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00164_RIGHT_CC.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00163_LEFT_CC.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00163_LEFT_CC.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00163_LEFT_MLO.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00163_LEFT_MLO.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00100_RIGHT_CC.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00100_RIGHT_CC.dcm\n",
      "Update [0008|103e]: Calc-Test_P_00100_RIGHT_MLO.dcm\n",
      "Update [0020|0060]: Calc-Test_P_00100_RIGHT_MLO.dcm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/223 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleanse: 46.85585880279541 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [01:27<00:00,  2.56it/s]\n",
      "100%|██████████| 26/26 [00:09<00:00,  2.77it/s]\n",
      "100%|██████████| 69/69 [00:24<00:00,  2.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# Transformation for breast density dataset\n",
    "train_transform = Compose( [\n",
    "    LoadImaged( keys='image'),\n",
    "    Lambdad(keys='image', func=lambda x: x.T),\n",
    "    AsChannelFirstd('image'),\n",
    "    RepeatChanneld('image', repeats=3),\n",
    "    Resized('image', spatial_size=(225,225), mode='nearest'),\n",
    "    ScaleIntensityd('image'), # scale data to 0~1\n",
    "    NormalizeIntensityd( 'image', \n",
    "                        subtrahend=[0.485, 0.456, 0.406],\n",
    "                        divisor=[0.229, 0.224, 0.225], \n",
    "                        channel_wise=True), # standardize with ImageNet weights\n",
    "    RandFlipd('image', spatial_axis=0, prob=0.5), \n",
    "    RandZoomd( 'image', min_zoom=0.9, max_zoom=1.5, prob=0.5, keep_size=True),\n",
    "    ToTensord( ('image', 'label') ),\n",
    "])\n",
    "\n",
    "val_transform = Compose( [\n",
    "    LoadImaged( keys='image'),\n",
    "    Lambdad(keys='image', func=lambda x: x.T),\n",
    "    AsChannelFirstd('image'),\n",
    "    RepeatChanneld('image', repeats=3),\n",
    "    Resized('image', spatial_size=(225,225), mode='nearest'),\n",
    "    ScaleIntensityd('image'),\n",
    "    NormalizeIntensityd( 'image', \n",
    "                        subtrahend=[0.485, 0.456, 0.406],\n",
    "                        divisor=[0.229, 0.224, 0.225], \n",
    "                        channel_wise=True), # standardize with ImageNet weights\n",
    "    ToTensord( ('image', 'label') ),\n",
    "])\n",
    "\n",
    "\n",
    "train_ds = CBISDDSMDataset( section='training', transforms=train_transform, download=[0])\n",
    "val_ds = CBISDDSMDataset( section='validation', transforms=val_transform, download=[0])\n",
    "test_ds = CBISDDSMDataset( section='test', transforms=val_transform, download=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-shelter",
   "metadata": {},
   "source": [
    "## Create Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-diamond",
   "metadata": {},
   "outputs": [],
   "source": [
    "localNode = Node( \"localhost\", 8000 ) # local server\n",
    "\n",
    "# If local node is crashed for some reason, you can try to load your Node\n",
    "# localNode = Node( 'localhost', 8000, node_uid )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-crime",
   "metadata": {},
   "source": [
    "## Add Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-found",
   "metadata": {},
   "outputs": [],
   "source": [
    "denseNet121 = densenet121(\n",
    "    spatial_dims=2,\n",
    "    in_channels=3,\n",
    "    out_channels=4, \n",
    "    pretrained=True\n",
    ")\n",
    "\n",
    "denseNet121.class_layers = torch.nn.Sequential( \n",
    "    torch.nn.ReLU( inplace=True ), \n",
    "    torch.nn.AdaptiveAvgPool2d( output_size=1),\n",
    "    torch.nn.Flatten(start_dim=1, end_dim=-1), \n",
    "    torch.nn.Linear(in_features=1024, out_features=4, bias=True),\n",
    "    torch.nn.Softmax()\n",
    ")\n",
    "\n",
    "denseNet169 = densenet169(spatial_dims=2, in_channels=3, out_channels=4, pretrained=True)\n",
    "denseNet169.class_layers = torch.nn.Sequential( \n",
    "    torch.nn.ReLU( inplace=True ), \n",
    "    torch.nn.AdaptiveAvgPool2d( output_size=1),\n",
    "    torch.nn.Flatten(start_dim=1, end_dim=-1), \n",
    "    torch.nn.Linear(in_features=1664, out_features=4, bias=True),\n",
    "    torch.nn.Softmax()\n",
    ")\n",
    "\n",
    "resnet50 = se_resnet50( spatial_dims=2, in_channels=3, num_classes=4, pretrained=True)\n",
    "resnet101 = se_resnet101( spatial_dims=2, in_channels=3, num_classes=4, pretrained=True)\n",
    "resnet152 = se_resnet152( spatial_dims=2, in_channels=3, num_classes=4, pretrained=True)\n",
    "resnet50.last_linear = torch.nn.Sequential( \n",
    "    torch.nn.Linear( in_features=2048, out_features=4, bias=True ), \n",
    "    torch.nn.Softmax()\n",
    ")\n",
    "resnet101.last_linear = torch.nn.Sequential( \n",
    "    torch.nn.Linear( in_features=2048, out_features=4, bias=True ), \n",
    "    torch.nn.Softmax()\n",
    ")\n",
    "resnet152.last_linear = torch.nn.Sequential( \n",
    "    torch.nn.Linear( in_features=2048, out_features=4, bias=True ), \n",
    "    torch.nn.Softmax()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "localNode.add_model([\n",
    "    Model(denseNet121, 'UIowa_denseNet121'), \n",
    "    Model(denseNet169, 'UIowa_denseNet169'), \n",
    "    Model(resnet50, 'UIowa_resnet50'), \n",
    "    Model(resnet101, 'UIowa_resnet101'), \n",
    "    Model(resnet152, 'UIowa_resnet152')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( localNode.model_bench) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-passage",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-qualification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper loss function\n",
    "def cross_entropy_with_onehot(input, target):\n",
    "    _, labels = target.max(dim=1)\n",
    "    return torch.nn.CrossEntropyLoss()(input, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-boutique",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print( 'device:', device )\n",
    "\n",
    "# temporary directory to save a snapshot\n",
    "# # update to your local directory\n",
    "temp_saveSnapshot_dir = '/local/vol00/home/bochoi/tmpModels/' \n",
    "\n",
    "histories = [None] * len(localNode.model_bench)\n",
    "for idx in range( len(localNode.model_bench) ):\n",
    "    print(localNode.model_bench[idx].name)\n",
    "    mkdir(temp_saveSnapshot_dir)\n",
    "\n",
    "    optimizer = torch.optim.Adam( localNode.model_bench[idx].net.parameters(), 5e-2) # 5e-3 was too big, doesn't train\n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau( optimizer, mode='min', factor=0.1, patience=50)\n",
    "    histories[idx] = localNode.model_bench[idx].train(\n",
    "        dataset=train_ds,\n",
    "        loss_function=cross_entropy_with_onehot,\n",
    "        optimizer=optimizer,\n",
    "        epochs=500,\n",
    "        metrics=[\"AUC\"],\n",
    "        batch_size=16,\n",
    "        device=device,\n",
    "        validation_dataset=val_ds,\n",
    "        dirpath=temp_saveSnapshot_dir, \n",
    "        earlystop={'patience':50, 'delta':0}\n",
    "    )\n",
    "    if len( os.listdir( temp_saveSnapshot_dir ) ) != 0:\n",
    "        localNode.model_bench[idx].load_snapshot(temp_saveSnapshot_dir)\n",
    "    \n",
    "    # save model's prediction performance\n",
    "    _, _ = localNode.model_bench[idx].predict( train_ds, section='train')\n",
    "    _, _ = localNode.model_bench[idx].predict( val_ds, section='validation')\n",
    "    _, _ = localNode.model_bench[idx].predict( test_ds, section='test')\n",
    "    \n",
    "    localNode.model_bench[idx].commit('initial commit')\n",
    "    remove( temp_saveSnapshot_dir)\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-monday",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "cols = 4\n",
    "plt.figure( figsize=(25, 5) ) \n",
    "\n",
    "plt.subplot( 1, cols, 1 )\n",
    "for model_history in histories:\n",
    "    plt.plot( model_history['loss'] )\n",
    "plt.title( 'training loss vs epoch' )\n",
    "plt.legend( [model.name for model in localNode.model_bench] )\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.subplot( 1, cols, 2 )\n",
    "for model_history in histories:\n",
    "    plt.plot( model_history['val_loss'] )\n",
    "plt.title( 'validation loss vs epoch' )\n",
    "plt.legend( [model.name for model in localNode.model_bench] )\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.subplot( 1, cols, 3 )\n",
    "for model_history in histories:\n",
    "    plt.plot( model_history['auc'] )\n",
    "plt.title( 'training auc vs epoch' )\n",
    "plt.legend( [model.name for model in localNode.model_bench] )\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.subplot( 1, cols, 4 )\n",
    "for model_history in histories:\n",
    "    plt.plot( model_history['val_auc'] )\n",
    "plt.title( 'validation auc vs epoch' )\n",
    "plt.legend( [model.name for model in localNode.model_bench] )\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-posting",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for model in localNode.model_bench:\n",
    "    print( model.name )\n",
    "    print( model.history )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-attachment",
   "metadata": {},
   "source": [
    "## Start your server \n",
    "\n",
    "(communicate through Slack) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "localNode.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-tragedy",
   "metadata": {},
   "source": [
    "## Send your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-medication",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# connect to the peers\n",
    "localNode.connect_to('Peer IP address', open port )\n",
    "localNode.connect_to('Another peer IP address', open port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-cincinnati",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for peer_idx in range( len(localNode.peers_outbound) ):\n",
    "    for model_idx in range( 5 ):\n",
    "        print( 'Sending', localNode.model_bench[model_idx].name, 'to', localNode.peers_outbound[peer_idx] )\n",
    "        localNode.send_model(peer_idx, model_index=model_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-coral",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(localNode.model_bench )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-import",
   "metadata": {},
   "source": [
    "## Create ensemble after recieving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-kuwait",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = localNode.create_ensemble( name='ensemble',\n",
    "                          size=3, \n",
    "                          dataset=val_ds,\n",
    "                          models=localNode.model_bench,\n",
    "                          diversity_measure='gd', \n",
    "                          test_dataset=test_ds,\n",
    "                          vote_method='majority'\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.create( percentage=0.25, \n",
    "               method='hill_climbing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.set_best_ensemble()\n",
    "ensemble.predict(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-paragraph",
   "metadata": {},
   "source": [
    "## Share the result to collaborators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-specification",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.save('path/to/save/the/ensembleResult')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
